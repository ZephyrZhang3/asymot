{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from diffusers import DDIMScheduler\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils import (\n",
    "    set_random_seed,\n",
    "    get_ddib_path,\n",
    "    get_flow_path,\n",
    "    cod_prob_bound,\n",
    ")\n",
    "\n",
    "from sampler import get_paired_dataset\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "SEED = 0x4090\n",
    "set_random_seed(SEED)\n",
    "\n",
    "# dataset choosing\n",
    "# DATASET, DATASET_PATH, IMG_SIZE, GRAY = \"usps2mnist\", \"./data/\", 28, True\n",
    "# DATASET, DATASET_PATH, IMG_SIZE, GRAY = \"mnist2fmnist\", \"./data/\", 28, True\n",
    "# DATASET, DATASET_PATH, IMG_SIZE, GRAY = \"fmnist2usps\", \"./data/\", 28, True\n",
    "\n",
    "\n",
    "DATASET, DATASET_PATH, IMG_SIZE, GRAY = (\n",
    "    \"comic_faces_v1\",\n",
    "    \"./data/face2comics_v1.0.0_by_Sxela\",\n",
    "    512,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# the step number adding noise in diffusion process\n",
    "DIFFUSION_STEPS = 100\n",
    "SCHEDULER = DDIMScheduler(num_train_timesteps=DIFFUSION_STEPS)\n",
    "PIVOTAL_LIST = [i for i in range(0, DIFFUSION_STEPS * 2 + 1, 100)]\n",
    "# PIVOTAL_LIST = [20, 50, 100]\n",
    "# All hyperparameters below is set to the values used for the experiments, which discribed in the article\n",
    "EPSILON = 0.1\n",
    "# R = 1000\n",
    "N = 2\n",
    "P = 1\n",
    "NUM_QUERY = 100\n",
    "MAX_NUM_SAMPLE = 6000\n",
    "\n",
    "# data sample settings\n",
    "SELECTED_CLASSES = [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        root,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        download=False,\n",
    "        selected_classes=None,\n",
    "        reverse=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.reverse = reverse\n",
    "\n",
    "        if name == \"usps2mnist\":\n",
    "            source = datasets.USPS(\n",
    "                os.path.join(root, \"USPS\", \"raw\"), train, transform, download=download\n",
    "            )\n",
    "            target = datasets.MNIST(root, train, transform, download=download)\n",
    "        elif name == \"mnist2fmnist\":\n",
    "            source = datasets.MNIST(root, train, transform, download=download)\n",
    "            target = datasets.FashionMNIST(root, train, transform, download=download)\n",
    "        elif name == \"fmnist2usps\":\n",
    "            source = datasets.FashionMNIST(root, train, transform, download=download)\n",
    "            target = datasets.USPS(\n",
    "                os.path.join(root, \"USPS\", \"raw\"), train, transform, download=download\n",
    "            )\n",
    "        else:\n",
    "            raise \"Invalid dataset name\"\n",
    "\n",
    "        if selected_classes is not None:\n",
    "            source_indices = [\n",
    "                i for i in range(len(source)) if source.targets[i] in selected_classes\n",
    "            ]\n",
    "            target_indices = [\n",
    "                i for i in range(len(target)) if target.targets[i] in selected_classes\n",
    "            ]\n",
    "        else:\n",
    "            source_indices = range(len(source))\n",
    "            target_indices = range(len(target))\n",
    "\n",
    "        source_indices = source_indices[: min(len(source), len(target))]\n",
    "        target_indices = target_indices[: min(len(source), len(target))]\n",
    "\n",
    "        self.x = Subset(source, source_indices)\n",
    "        self.y = Subset(target, target_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = (self.x)[idx][0], (self.y)[idx][0]\n",
    "\n",
    "        return (x, y) if not self.reverse else (y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET in [\"mnist2fmnist\", \"usps2mnist\", \"fmnist2usps\"]:\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            ToTensor(),\n",
    "            Normalize((0.5), (0.5)),\n",
    "        ]\n",
    "    )\n",
    "    dataset = PairedDataset2(\n",
    "        DATASET,\n",
    "        DATASET_PATH,\n",
    "        transform=transform,\n",
    "        selected_classes=SELECTED_CLASSES,\n",
    "    )\n",
    "\n",
    "elif DATASET == \"comic_faces_v1\":\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            ToTensor(),\n",
    "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "    dataset, _ = get_paired_dataset(\n",
    "        DATASET,\n",
    "        DATASET_PATH,\n",
    "        transform,\n",
    "    )\n",
    "else:\n",
    "    raise \"Invalid dataset\"\n",
    "\n",
    "if len(dataset) > MAX_NUM_SAMPLE:\n",
    "    dataset = Subset(dataset, range(MAX_NUM_SAMPLE))\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    type(dataset[0][0]),\n",
    "    round(sys.getsizeof(dataset[0][0]) * 2 * len(dataset) * 2000 / (1024 * 1024), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_point(x, gray=GRAY):\n",
    "    if gray:\n",
    "        plt.imshow(x.squeeze().numpy(), cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(x.squeeze().permute(1, 2, 0).numpy())\n",
    "    plt.axis(\"off\")  # 不显示坐标轴\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_data_point(dataset[0][0])\n",
    "plot_data_point(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def plot_path(\n",
    "    path: Union[list, torch.Tensor],\n",
    "    indices: list = None,\n",
    "    gray: bool = False,\n",
    "):\n",
    "    if indices is not None:\n",
    "        path = [path[i] for i in indices]\n",
    "    if isinstance(path, list):\n",
    "        path = torch.stack(path)\n",
    "\n",
    "    imgs: np.ndarray = (\n",
    "        path.to(\"cpu\").permute(0, 2, 3, 1).mul(0.5).add(0.5).numpy().clip(0, 1)\n",
    "    )\n",
    "\n",
    "    if len(path) < 10:\n",
    "        ncols = len(path)\n",
    "        nrows = 1\n",
    "    else:\n",
    "        ncols = 10\n",
    "        nrows = len(path) // 10 + 1\n",
    "\n",
    "    fig = plt.figure(figsize=(1.5 * ncols, 1.5 * nrows), dpi=150)\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = fig.add_subplot(nrows, ncols, i + 1)\n",
    "        if gray:\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_title(f\"$X_{{{i}}}$\", fontsize=16)\n",
    "        if i == imgs.shape[0] - 1:\n",
    "            ax.set_title(\"Y\", fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concentration of Distance Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDIB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate asymptotic distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (1, IMG_SIZE, IMG_SIZE) if GRAY else (3, IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "x2y_ddib_asymptotic_dataset = torch.empty(\n",
    "    (DIFFUSION_STEPS * 2 + 1, len(dataset), *image_shape), dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: 512图片内存占用巨大，需要优化（或者服务器运行尝试）\n",
    "for i, (x, y) in enumerate(tqdm(dataset)):\n",
    "    path = get_ddib_path(x, y, SCHEDULER)\n",
    "    x2y_ddib_asymptotic_dataset[:, i] = path\n",
    "\n",
    "# x2y_ddib_path_list = torch.stack(x2y_ddib_path_list)\n",
    "# x2y_ddib_asymptotic_dataset = x2y_ddib_path_list.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2y_ddib_asymptotic_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path(\n",
    "    x2y_ddib_asymptotic_dataset[:, 0],\n",
    "    # indices=PIVOTAL_LIST,\n",
    "    gray=GRAY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caculate CoD Prob Bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_step = x2y_ddib_asymptotic_dataset.shape[0] // 2\n",
    "\n",
    "Q_point_indices = np.random.choice(\n",
    "    x2y_ddib_asymptotic_dataset.shape[1], NUM_QUERY, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_dataset = x2y_ddib_asymptotic_dataset[0][Q_point_indices]\n",
    "T_point_dataset = x2y_ddib_asymptotic_dataset[-1]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2y_ddim_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={0} -> t={x2y_ddib_asymptotic_dataset.shape[0]-1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2y_ddim_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_dataset = x2y_ddib_asymptotic_dataset[0][Q_point_indices]\n",
    "T_point_dataset = x2y_ddib_asymptotic_dataset[mid_step]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2g_ddim_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={0} -> t={mid_step}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2g_ddim_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_dataset = x2y_ddib_asymptotic_dataset[mid_step][Q_point_indices]\n",
    "T_point_dataset = x2y_ddib_asymptotic_dataset[-1]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "g2y_ddim_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={mid_step} -> t={x2y_ddib_asymptotic_dataset.shape[0] - 1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={g2y_ddim_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2y_ddim_prob_bound_list = []\n",
    "for t in range(x2y_ddib_asymptotic_dataset.shape[0] - 1):\n",
    "    Q_point_dataset = x2y_ddib_asymptotic_dataset[t][Q_point_indices]\n",
    "    T_point_dataset = x2y_ddib_asymptotic_dataset[t + 1]\n",
    "\n",
    "    # plot_data_point(Q_point)\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_point_dataset:\n",
    "        prob_bound = cod_prob_bound(\n",
    "            T_point_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "        )\n",
    "        prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    print(f\"t={t} -> t={t+1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")\n",
    "\n",
    "    x2y_ddim_prob_bound_list.append(prob_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(mid_step, 0, 1, colors=\"black\")\n",
    "\n",
    "plt.hlines(x2y_ddim_prob_bound, 0, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "plt.hlines(x2g_ddim_prob_bound, 0, mid_step, colors=\"red\")\n",
    "plt.hlines(g2y_ddim_prob_bound, mid_step, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "\n",
    "for t, prob in enumerate(x2y_ddim_prob_bound_list):\n",
    "    plt.hlines(prob, t, t + 1)\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(f\"Lower Bound of P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}\")\n",
    "\n",
    "plt.xlim(0, DIFFUSION_STEPS * 2)\n",
    "plt.ylim(0, 1)\n",
    "plt.margins(x=0)\n",
    "plt.title(f\"DDIB: {DATASET}, $\\epsilon$={EPSILON}, {DIFFUSION_STEPS} steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate asymptotic distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2y_flow_path_list = []\n",
    "for x, y in tqdm(dataset):\n",
    "    path = get_flow_path(x, y, DIFFUSION_STEPS + 1)\n",
    "    path = torch.stack(path)\n",
    "    x2y_flow_path_list.append(path)\n",
    "\n",
    "x2y_flow_path_list = torch.stack(x2y_flow_path_list)\n",
    "x2y_flow_asymptotic_dataset = x2y_flow_path_list.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path(\n",
    "    x2y_flow_path_list[0],\n",
    "    indices=PIVOTAL_LIST,\n",
    "    gray=GRAY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caculate CoD Prob Bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_indices = np.random.choice(\n",
    "    x2y_flow_path_list.shape[0], NUM_QUERY, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_dataset = x2y_flow_asymptotic_dataset[0][Q_point_indices]\n",
    "T_point_dataset = x2y_flow_asymptotic_dataset[-1]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2y_flow_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={0} -> t={x2y_flow_asymptotic_dataset.shape[0]-1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2y_flow_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2y_flow_prob_bound_list = []\n",
    "for t in range(x2y_flow_asymptotic_dataset.shape[0] - 1):\n",
    "    Q_point_dataset = x2y_flow_asymptotic_dataset[t][Q_point_indices]\n",
    "    T_point_dataset = x2y_flow_asymptotic_dataset[t + 1]\n",
    "\n",
    "    # plot_data_point(Q_point)\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_point_dataset:\n",
    "        prob_bound = cod_prob_bound(\n",
    "            T_point_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "        )\n",
    "        prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    print(f\"t={t} -> t={t+1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")\n",
    "\n",
    "    x2y_flow_prob_bound_list.append(prob_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hlines(x2y_flow_prob_bound, 0, DIFFUSION_STEPS, colors=\"red\")\n",
    "\n",
    "\n",
    "for t, prob in enumerate(x2y_flow_prob_bound_list):\n",
    "    plt.hlines(prob, t, t + 1)\n",
    "\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(f\"Lower Bound of P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}\")\n",
    "\n",
    "plt.xlim(0, DIFFUSION_STEPS)\n",
    "plt.ylim(0, 0.5 if x2y_flow_prob_bound < 0.5 else 1)\n",
    "plt.margins(x=0)\n",
    "plt.title(f\"Flow: {DATASET}, $\\epsilon$={EPSILON}, {DIFFUSION_STEPS} steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO LIST\n",
    "\n",
    "1. 数据集加载\n",
    "   - [√] FMNIST, MNIST, USPS\n",
    "   - [√] comic_faces_v1\n",
    "2. 多种渐变方式\n",
    "   - [√] 扩散(DDIM)：并无直接 X->Y 的分布转移渐变，只有 X->高斯->Y 分布。但高斯分布本身会造成严重距离聚集。\n",
    "   - [√] Flow(插值)：X->Y 分布转移渐变，纯粹生成一般随机采样高斯噪声作为 X。\n",
    "   - [] 薛定谔桥：同 Flow\n",
    "3. [√]CoD 概率下界计算\n",
    "4. []画图\n",
    "   - [√] 直接\n",
    "   - [√] 逐步\n",
    "   - [] 选取节点：加噪 1000 步，选取个别节点\n",
    "5. []级联 OT\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
