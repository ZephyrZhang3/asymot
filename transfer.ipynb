{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from diffusers import DDIMScheduler\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils import (\n",
    "    set_random_seed,\n",
    "    add_ddim_noise_at_t_step,\n",
    "    add_ddim_noise_t_times,\n",
    "    qiuck_ddim_noise_t_times,\n",
    "    get_ddim_path,\n",
    "    get_ddib_path,\n",
    "    cod_prob_bound,\n",
    "    estimate_cod_prob_bound,\n",
    ")\n",
    "\n",
    "from sampler import get_paired_dataset\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "SEED = 0x4090\n",
    "set_random_seed(SEED)\n",
    "\n",
    "# dataset choosing\n",
    "# DATASET, DATASET_PATH, IMG_SIZE, GRAY = \"mnist2usps\", \"./data/\", 28, True\n",
    "# DATASET, DATASET_PATH, IMG_SIZE, GRAY = \"fmnist2mnist\", \"./data/\", 28, True\n",
    "# DATASET, DATASET_PATH, IMG_SIZE, GRAY = \"usps2fmnist\", \"./data/\", 28, True\n",
    "\n",
    "\n",
    "DATASET, DATASET_PATH, IMG_SIZE, GRAY = (\n",
    "    \"comic_faces_v1\",\n",
    "    \"./data/face2comics_v1.0.0_by_Sxela\",\n",
    "    256,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# the step number adding noise in diffusion process\n",
    "DIFFUSION_STEPS = 1000\n",
    "SCHEDULER = DDIMScheduler(num_train_timesteps=DIFFUSION_STEPS)\n",
    "PIVOTAL_LIST = [10, 20, 30]\n",
    "# PIVOTAL_LIST = [20, 50, 100]\n",
    "# All hyperparameters below is set to the values used for the experiments, which discribed in the article\n",
    "EPSILON = 0.3\n",
    "R = 900  # or len(dataset) dataset estimation sample size\n",
    "N = 2\n",
    "P = 1\n",
    "NUM_QUERY = 10\n",
    "# data sample settings\n",
    "SELECTED_CLASSES = [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedDataset2(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        root,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        download=False,\n",
    "        selected_classes=None,\n",
    "        reverse=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.reverse = reverse\n",
    "\n",
    "        if name == \"usps2fmnist\":\n",
    "            source = datasets.USPS(\n",
    "                os.path.join(root, \"USPS\", \"raw\"), train, transform, download=download\n",
    "            )\n",
    "            target = datasets.FashionMNIST(root, train, transform, download=download)\n",
    "        elif name == \"fmnist2mnist\":\n",
    "            source = datasets.FashionMNIST(root, train, transform, download=download)\n",
    "            target = datasets.MNIST(root, train, transform, download=download)\n",
    "        elif name == \"mnist2usps\":\n",
    "            source = datasets.MNIST(root, train, transform, download=download)\n",
    "            target = datasets.USPS(\n",
    "                os.path.join(root, \"USPS\", \"raw\"), train, transform, download=download\n",
    "            )\n",
    "        else:\n",
    "            raise \"Invalid dataset name\"\n",
    "\n",
    "        if selected_classes is not None:\n",
    "            source_indices = [\n",
    "                i for i in range(len(source)) if source.targets[i] in selected_classes\n",
    "            ]\n",
    "            target_indices = [\n",
    "                i for i in range(len(target)) if target.targets[i] in selected_classes\n",
    "            ]\n",
    "        else:\n",
    "            source_indices = range(len(source))\n",
    "            target_indices = range(len(target))\n",
    "\n",
    "        source_indices = source_indices[: min(len(source_indices), len(target_indices))]\n",
    "        target_indices = target_indices[: min(len(source_indices), len(target_indices))]\n",
    "\n",
    "        self.x = Subset(source, source_indices)\n",
    "        self.y = Subset(target, target_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = (self.x)[idx][0], (self.y)[idx][0]\n",
    "\n",
    "        return (x, y) if not self.reverse else (y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET in [\"usps2fmnist\", \"fmnist2mnist\", \"mnist2usps\"]:\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            ToTensor(),\n",
    "            Normalize((0.5), (0.5)),\n",
    "        ]\n",
    "    )\n",
    "    dataset = PairedDataset2(\n",
    "        DATASET,\n",
    "        DATASET_PATH,\n",
    "        transform=transform,\n",
    "        selected_classes=SELECTED_CLASSES,\n",
    "    )\n",
    "\n",
    "elif DATASET == \"comic_faces_v1\":\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            ToTensor(),\n",
    "            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "    dataset, _ = get_paired_dataset(\n",
    "        DATASET,\n",
    "        DATASET_PATH,\n",
    "        transform,\n",
    "    )\n",
    "else:\n",
    "    raise \"Invalid dataset\"\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset[0][0]), dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Subset(\n",
    "    dataset,\n",
    "    random.choices(range(len(dataset)), k=min(R, len(dataset))),\n",
    ")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_point(x, gray=GRAY):\n",
    "    if gray:\n",
    "        plt.imshow(x.squeeze().numpy(), cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(x.squeeze().permute(1, 2, 0).numpy())\n",
    "    plt.axis(\"off\")  # 不显示坐标轴\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_data_point(dataset[0][0])\n",
    "plot_data_point(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def plot_path(\n",
    "    path: Union[list, torch.Tensor],\n",
    "    indices: list = None,\n",
    "    gray: bool = False,\n",
    "):\n",
    "    if indices is not None:\n",
    "        path = [path[i] for i in indices]\n",
    "    if isinstance(path, list):\n",
    "        path = torch.stack(path)\n",
    "\n",
    "    imgs: np.ndarray = (\n",
    "        path.to(\"cpu\").permute(0, 2, 3, 1).mul(0.5).add(0.5).numpy().clip(0, 1)\n",
    "    )\n",
    "\n",
    "    if len(path) < 10:\n",
    "        ncols = len(path)\n",
    "        nrows = 1\n",
    "    else:\n",
    "        ncols = 10\n",
    "        nrows = len(path) // 10 + 1\n",
    "\n",
    "    fig = plt.figure(figsize=(1.5 * ncols, 1.5 * nrows), dpi=150)\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = fig.add_subplot(nrows, ncols, i + 1)\n",
    "        if gray:\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_title(f\"$X_{{{i}}}$\", fontsize=16)\n",
    "        if i == imgs.shape[0] - 1:\n",
    "            ax.set_title(\"Y\", fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concentration of Distance Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDIB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate asymptotic distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: 512图片内存占用巨大，需要优化（或者服务器运行尝试）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2self_prob_bound = None\n",
    "y2self_prob_bound = None\n",
    "\n",
    "x2y_prob_bound = None\n",
    "x2g_ddim_prob_bound_list = []\n",
    "x2g_prob_bound = None\n",
    "g2y_ddim_prob_bound_list = []\n",
    "g2y_prob_bound = None\n",
    "\n",
    "Q_point_indices = np.random.choice(len(dataset), NUM_QUERY, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2y_ddib_asymptotic_neighbor_dataset = torch.empty(\n",
    "    (2, len(dataset), *image_shape), dtype=torch.float32\n",
    ")\n",
    "x2y_ddib_asymptotic_neighbor_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[0][i] = dataset[i][0]\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[1][i] = dataset[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[0][Q_point_indices]\n",
    "T_dataset = x2y_ddib_asymptotic_neighbor_dataset[0]\n",
    "\n",
    "plot_data_point(Q_dataset[0])\n",
    "plot_data_point(T_dataset[0])\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_dataset:\n",
    "    prob_bound = estimate_cod_prob_bound(\n",
    "        T_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "        P,\n",
    "        R,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2self_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(f\"x -> x: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2self_prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[1][Q_point_indices]\n",
    "T_dataset = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "plot_data_point(Q_dataset[0])\n",
    "plot_data_point(T_dataset[0])\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_dataset:\n",
    "    prob_bound = estimate_cod_prob_bound(\n",
    "        T_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "        P,\n",
    "        R,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "y2self_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(f\"y -> y: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={y2self_prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[0][Q_point_indices]\n",
    "T_dataset = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "\n",
    "plot_data_point(Q_dataset[3])\n",
    "plot_data_point(T_dataset[3])\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_dataset:\n",
    "    prob_bound = estimate_cod_prob_bound(\n",
    "        T_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "        P,\n",
    "        R,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2y_prob_bound = prob_bound_list.mean()\n",
    "print(f\"x -> y: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2y_prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[1][Q_point_indices]\n",
    "T_dataset = x2y_ddib_asymptotic_neighbor_dataset[0]\n",
    "\n",
    "plot_data_point(Q_dataset[3])\n",
    "plot_data_point(T_dataset[3])\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_dataset:\n",
    "    prob_bound = estimate_cod_prob_bound(\n",
    "        T_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "        P,\n",
    "        R,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "y2x_prob_bound = prob_bound_list.mean()\n",
    "print(f\"y -> x: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={y2x_prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(DIFFUSION_STEPS):\n",
    "    for i, x in enumerate(x2y_ddib_asymptotic_neighbor_dataset[0]):\n",
    "        x_next = add_ddim_noise_at_t_step(x, t, SCHEDULER)\n",
    "        x2y_ddib_asymptotic_neighbor_dataset[1, i] = x_next\n",
    "\n",
    "    Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[0][Q_point_indices]\n",
    "    T_dataset = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "\n",
    "    if t in PIVOTAL_LIST:\n",
    "        plot_data_point(x2y_ddib_asymptotic_neighbor_dataset[0][0])\n",
    "        plot_data_point(x2y_ddib_asymptotic_neighbor_dataset[1][0])\n",
    "\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_dataset:\n",
    "        prob_bound = estimate_cod_prob_bound(\n",
    "            T_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "            P,\n",
    "            R,\n",
    "        )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    x2g_ddim_prob_bound_list.append(prob_bound)\n",
    "\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[0] = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "\n",
    "    print(f\"x{t}->x{t+1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[0][i] = dataset[i][0]\n",
    "\n",
    "Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[0][Q_point_indices]\n",
    "T_dataset = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "\n",
    "plot_data_point(Q_dataset[0])\n",
    "plot_data_point(T_dataset[0])\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_dataset:\n",
    "    prob_bound = estimate_cod_prob_bound(\n",
    "        T_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "        P,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2g_prob_bound = prob_bound_list.mean()\n",
    "print(f\"x -> g: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2g_prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[0][i] = dataset[i][1]\n",
    "g2y_ddim_prob_bound_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(DIFFUSION_STEPS):\n",
    "    for i, y in enumerate(x2y_ddib_asymptotic_neighbor_dataset[0]):\n",
    "        y_prev = add_ddim_noise_at_t_step(y, t, SCHEDULER)\n",
    "        x2y_ddib_asymptotic_neighbor_dataset[1, i] = y_prev\n",
    "\n",
    "    Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[1][Q_point_indices]\n",
    "    T_dataset = x2y_ddib_asymptotic_neighbor_dataset[0]\n",
    "\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_dataset:\n",
    "        prob_bound = estimate_cod_prob_bound(\n",
    "            T_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "        )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    print(f\"y{t + 1}->y{t}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")\n",
    "    g2y_ddim_prob_bound_list.append(prob_bound)\n",
    "\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[0] = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "\n",
    "g2y_ddim_prob_bound_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    x2y_ddib_asymptotic_neighbor_dataset[1][i] = dataset[i][1]\n",
    "\n",
    "Q_dataset = x2y_ddib_asymptotic_neighbor_dataset[0][Q_point_indices]\n",
    "T_dataset = x2y_ddib_asymptotic_neighbor_dataset[1]\n",
    "\n",
    "plot_data_point(Q_dataset[0])\n",
    "plot_data_point(T_dataset[0])\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_dataset:\n",
    "    prob_bound = estimate_cod_prob_bound(\n",
    "        T_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "g2y_prob_bound = prob_bound_list.mean()\n",
    "print(f\"g -> y: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={g2y_prob_bound:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(DIFFUSION_STEPS, 0, 1, colors=\"black\")\n",
    "\n",
    "\n",
    "plt.hlines(x2g_prob_bound, 0, DIFFUSION_STEPS, colors=\"red\")\n",
    "plt.hlines(g2y_prob_bound, DIFFUSION_STEPS, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "plt.hlines(x2y_prob_bound, 0, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "plt.hlines(y2x_prob_bound, 0, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "\n",
    "plt.scatter(0, x2self_prob_bound, c=\"pink\")\n",
    "plt.scatter(2 * DIFFUSION_STEPS, y2self_prob_bound, c=\"pink\")\n",
    "# plt.hlines(x2g_ddim_prob_bound, 0, mid_step, colors=\"red\")\n",
    "# plt.hlines(g2y_ddim_prob_bound, mid_step, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "\n",
    "t = np.arange(0, DIFFUSION_STEPS)\n",
    "\n",
    "plt.plot(t, x2g_ddim_prob_bound_list, color=\"green\", lw=1)\n",
    "plt.plot(t, x2g_ddim_prob_bound_list, color=\"green\", lw=2, alpha=0.2)\n",
    "t = np.arange(DIFFUSION_STEPS, DIFFUSION_STEPS * 2)\n",
    "plt.plot(t, g2y_ddim_prob_bound_list, color=\"blue\", lw=1)\n",
    "plt.plot(t, g2y_ddim_prob_bound_list, color=\"blue\", lw=2, alpha=0.2)\n",
    "\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(f\"Lower Bound of P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}\")\n",
    "\n",
    "plt.xlim(0, DIFFUSION_STEPS * 2 + 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.margins(x=0)\n",
    "plt.title(f\"DDIB: {DATASET}, $\\epsilon$={EPSILON}, {DIFFUSION_STEPS} steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO LIST\n",
    "\n",
    "1. 数据集\n",
    "   - [√] FMNIST, MNIST, USPS\n",
    "   - [] comic_faces_v1\n",
    "   - [] celeba mask\n",
    "2. 多种渐变方式\n",
    "   - [√] 扩散(DDIM)：并无直接 X->Y 的分布转移渐变，只有 X->高斯->Y 分布。但高斯分布本身会造成严重距离聚集。\n",
    "   - [√] Flow(插值)：X->Y 分布转移渐变，纯粹生成一般随机采样高斯噪声作为 X。\n",
    "   - [] 薛定谔桥：同 Flow\n",
    "3. []CoD 概率下界计算\n",
    "   - [√] 直接\n",
    "   - [√] 逐步\n",
    "   - [] 选取节点：加噪 1000 步，选取个别节点\n",
    "4. [√]画图\n",
    "5. []级联 OT\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
