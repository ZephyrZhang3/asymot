{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from diffusers import DDIMScheduler\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils import (\n",
    "    set_random_seed,\n",
    "    get_ddim_path,\n",
    "    get_flow_path,\n",
    "    cod_prob_bound,\n",
    ")\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "SEED = 0x4090\n",
    "set_random_seed(SEED)\n",
    "\n",
    "# dataset choosing\n",
    "# DATASET, DATASET_PATH = \"fmnist2mnist\", \"./data/\"\n",
    "# DATASET, DATASET_PATH = \"usps2mnist\", \"./data/\"\n",
    "# DATASET, DATASET_PATH = \"mnist2fmnist\", \"./data/\"\n",
    "DATASET, DATASET_PATH = \"usps2fmnist\", \"./data/\"\n",
    "\n",
    "IMG_SIZE = 28\n",
    "\n",
    "# the step number adding noise in diffusion process\n",
    "DIFFUSION_STEPS = 100\n",
    "SCHEDULER = DDIMScheduler(num_train_timesteps=DIFFUSION_STEPS)\n",
    "PIVOTAL_LIST = None\n",
    "# PIVOTAL_LIST = [20, 50, 100]\n",
    "# All hyperparameters below is set to the values used for the experiments, which discribed in the article\n",
    "EPSILON = 0.25\n",
    "# R = 1000\n",
    "N = 2\n",
    "P = 1\n",
    "NUM_QUERY = 10\n",
    "\n",
    "# data sample settings\n",
    "SUBSET_CLASS = 2\n",
    "\n",
    "# plot settings\n",
    "GRAY_PLOTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize samplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_transform = Compose(\n",
    "    [\n",
    "        Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        ToTensor(),\n",
    "        Normalize((0.5), (0.5)),\n",
    "    ]\n",
    ")\n",
    "target_transform = source_transform\n",
    "\n",
    "if DATASET == \"fmnist2mnist\":\n",
    "    source = datasets.FashionMNIST\n",
    "    target = datasets.MNIST\n",
    "elif DATASET == \"usps2mnist\":\n",
    "    source = datasets.USPS\n",
    "    target = datasets.MNIST\n",
    "elif DATASET == \"usps2fmnist\":\n",
    "    source = datasets.USPS\n",
    "    target = datasets.FashionMNIST\n",
    "else:\n",
    "    raise \"Invalid dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = source(\n",
    "    root=DATASET_PATH, train=True, download=True, transform=source_transform\n",
    ")\n",
    "target_dataset = target(\n",
    "    root=DATASET_PATH, train=True, download=True, transform=target_transform\n",
    ")\n",
    "\n",
    "source_indices = [\n",
    "    i for i, label in enumerate(source_dataset.targets) if label == SUBSET_CLASS\n",
    "]\n",
    "target_indices = [\n",
    "    i for i, label in enumerate(target_dataset.targets) if label == SUBSET_CLASS\n",
    "]\n",
    "\n",
    "source_dataset = Subset(source_dataset, source_indices)\n",
    "target_dataset = Subset(target_dataset, target_indices)\n",
    "\n",
    "len(source_dataset), len(target_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_point(x):\n",
    "    plt.imshow(x.squeeze().numpy(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")  # 不显示坐标轴\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_data_point(source_dataset[0][0])\n",
    "plot_data_point(target_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "def plot_path(\n",
    "    path: Union[list, torch.Tensor],\n",
    "    indices: list = None,\n",
    "    gray: bool = False,\n",
    "):\n",
    "    if indices is not None:\n",
    "        path = [path[i] for i in indices]\n",
    "    if isinstance(path, list):\n",
    "        path = torch.stack(path)\n",
    "\n",
    "    imgs: np.ndarray = (\n",
    "        path.to(\"cpu\").permute(0, 2, 3, 1).mul(0.5).add(0.5).numpy().clip(0, 1)\n",
    "    )\n",
    "\n",
    "    if len(path) < 10:\n",
    "        ncols = len(path)\n",
    "        nrows = 1\n",
    "    else:\n",
    "        ncols = 10\n",
    "        nrows = len(path) // 10 + 1\n",
    "\n",
    "    fig = plt.figure(figsize=(1.5 * ncols, 1.5 * nrows), dpi=150)\n",
    "    for i, img in enumerate(imgs):\n",
    "        ax = fig.add_subplot(nrows, ncols, i + 1)\n",
    "        if gray:\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_title(f\"$X_{{{i}}}$\", fontsize=16)\n",
    "        if i == imgs.shape[0] - 1:\n",
    "            ax.set_title(\"Y\", fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concentration of Distance Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDIM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X2G: generate asymptotic distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path_list = []\n",
    "for x, _ in tqdm(source_dataset, total=len(source_dataset)):\n",
    "    path = get_ddim_path(x, SCHEDULER, reverse=False)\n",
    "    path = torch.stack(path)\n",
    "    x_path_list.append(path)\n",
    "\n",
    "x_path_list = torch.stack(x_path_list)\n",
    "x2g_asymptotic_dataset = x_path_list.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path(\n",
    "    x_path_list[0],\n",
    "    # indices=PIVOTAL_LIST,\n",
    "    gray=GRAY_PLOTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X2G: caculate CoD Prob Bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_indices = np.random.choice(x_path_list.shape[0], NUM_QUERY, replace=False)\n",
    "Q_point_dataset = x2g_asymptotic_dataset[0][Q_point_indices]\n",
    "T_point_dataset = x2g_asymptotic_dataset[-1]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2g_ddim_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={0} -> t={x2g_asymptotic_dataset.shape[0]-1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2g_ddim_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2g_ddim_prob_bound_list = []\n",
    "for t in range(x2g_asymptotic_dataset.shape[0] - 1):\n",
    "    Q_point_dataset = x2g_asymptotic_dataset[t][Q_point_indices]\n",
    "    T_point_dataset = x2g_asymptotic_dataset[t + 1]\n",
    "\n",
    "    # plot_data_point(Q_point)\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_point_dataset:\n",
    "        prob_bound = cod_prob_bound(\n",
    "            T_point_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "        )\n",
    "        prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    print(f\"t={t} -> t={t+1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")\n",
    "\n",
    "    x2g_ddim_prob_bound_list.append(prob_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G2Y: generate asymptotic distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_path_list = []\n",
    "for y, _ in tqdm(target_dataset, total=len(target_dataset)):\n",
    "    path = get_ddim_path(y, SCHEDULER)\n",
    "    path = torch.stack(path)\n",
    "    y_path_list.append(path)\n",
    "\n",
    "y_path_list = torch.stack(y_path_list)\n",
    "g2y_asymptotic_dataset = y_path_list.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_path_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path(\n",
    "    y_path_list[0],\n",
    "    indices=PIVOTAL_LIST,\n",
    "    gray=GRAY_PLOTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G2Y: caculate CoD Prob Bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_indices = np.random.choice(y_path_list.shape[0], NUM_QUERY, replace=False)\n",
    "Q_point_dataset = g2y_asymptotic_dataset[0][Q_point_indices]\n",
    "T_point_dataset = g2y_asymptotic_dataset[-1]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "g2y_ddim_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={0} -> t={g2y_asymptotic_dataset.shape[0]-1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={g2y_ddim_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2y_ddim_prob_bound_list = []\n",
    "for t in range(g2y_asymptotic_dataset.shape[0] - 1):\n",
    "    Q_point_dataset = g2y_asymptotic_dataset[t][Q_point_indices]\n",
    "    T_point_dataset = g2y_asymptotic_dataset[t + 1]\n",
    "\n",
    "    # plot_data_point(Q_point)\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_point_dataset:\n",
    "        prob_bound = cod_prob_bound(\n",
    "            T_point_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "        )\n",
    "        prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    print(f\"t={t} -> t={t+1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")\n",
    "\n",
    "    g2y_ddim_prob_bound_list.append(prob_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g2y_ddim_prob_bound_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate asymptotic distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path_list = []\n",
    "for (x, _), (y, _) in tqdm(\n",
    "    zip(source_dataset, target_dataset),\n",
    "    total=min(len(source_dataset), len(target_dataset)),\n",
    "):\n",
    "    path = get_flow_path(x, y, DIFFUSION_STEPS + 1)\n",
    "    path = torch.stack(path)\n",
    "    flow_path_list.append(path)\n",
    "\n",
    "flow_path_list = torch.stack(flow_path_list)\n",
    "x2y_flow_asymptotic_dataset = flow_path_list.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path(\n",
    "    flow_path_list[0],\n",
    "    indices=PIVOTAL_LIST,\n",
    "    gray=GRAY_PLOTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caculate CoD Prob Bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_indices = np.random.choice(flow_path_list.shape[0], NUM_QUERY, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_point_dataset = x2y_flow_asymptotic_dataset[0][Q_point_indices]\n",
    "T_point_dataset = x2y_flow_asymptotic_dataset[-1]\n",
    "\n",
    "prob_bound_list = []\n",
    "for Q_point in Q_point_dataset:\n",
    "    prob_bound = cod_prob_bound(\n",
    "        T_point_dataset,\n",
    "        EPSILON,\n",
    "        Q_point,\n",
    "        \"euclidean\",\n",
    "        N,\n",
    "    )\n",
    "    prob_bound_list.append(prob_bound)\n",
    "prob_bound_list = np.array(prob_bound_list)\n",
    "x2y_flow_prob_bound = prob_bound_list.mean()\n",
    "\n",
    "print(\n",
    "    f\"t={0} -> t={x2y_flow_asymptotic_dataset.shape[0]-1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={x2y_flow_prob_bound:.4%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2y_flow_prob_bound_list = []\n",
    "for t in range(x2y_flow_asymptotic_dataset.shape[0] - 1):\n",
    "    Q_point_dataset = x2y_flow_asymptotic_dataset[t][Q_point_indices]\n",
    "    T_point_dataset = x2y_flow_asymptotic_dataset[t + 1]\n",
    "\n",
    "    # plot_data_point(Q_point)\n",
    "    prob_bound_list = []\n",
    "    for Q_point in Q_point_dataset:\n",
    "        prob_bound = cod_prob_bound(\n",
    "            T_point_dataset,\n",
    "            EPSILON,\n",
    "            Q_point,\n",
    "            \"euclidean\",\n",
    "            N,\n",
    "        )\n",
    "        prob_bound_list.append(prob_bound)\n",
    "    prob_bound_list = np.array(prob_bound_list)\n",
    "    prob_bound = prob_bound_list.mean()\n",
    "    print(f\"t={t} -> t={t+1}: P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}>={prob_bound:.4%}\")\n",
    "\n",
    "    x2y_flow_prob_bound_list.append(prob_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hlines(x2y_flow_prob_bound, 0, DIFFUSION_STEPS, colors=\"red\")\n",
    "\n",
    "\n",
    "for t, prob in enumerate(x2y_flow_prob_bound_list):\n",
    "    plt.hlines(prob, t, t + 1)\n",
    "\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(f\"Lower Bound of P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}\")\n",
    "\n",
    "plt.xlim(0, DIFFUSION_STEPS)\n",
    "plt.ylim(0, 0.5 if x2y_flow_prob_bound < 0.5 else 1)\n",
    "plt.margins(x=0)\n",
    "plt.title(f\"Flow: {DATASET}, $\\epsilon$={EPSILON}, {DIFFUSION_STEPS} steps\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2g_ddim_prob_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(DIFFUSION_STEPS, 0, 1, colors=\"black\")\n",
    "\n",
    "plt.hlines(x2g_ddim_prob_bound, 0, DIFFUSION_STEPS, colors=\"red\")\n",
    "plt.hlines(g2y_ddim_prob_bound, DIFFUSION_STEPS, DIFFUSION_STEPS * 2, colors=\"red\")\n",
    "\n",
    "for t, prob in enumerate(x2g_ddim_prob_bound_list):\n",
    "    plt.hlines(prob, t, t + 1)\n",
    "for t, prob in enumerate(g2y_ddim_prob_bound_list):\n",
    "    plt.hlines(prob, DIFFUSION_STEPS + t, DIFFUSION_STEPS + t + 1)\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(f\"Lower Bound of P{{DMAX({N})<=(1+{EPSILON})DMIN({N})}}\")\n",
    "\n",
    "plt.xlim(0, DIFFUSION_STEPS * 2)\n",
    "plt.ylim(0, 1)\n",
    "plt.margins(x=0)\n",
    "plt.title(f\"DDIM: {DATASET}, $\\epsilon$={EPSILON}, {DIFFUSION_STEPS} steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO LIST\n",
    "\n",
    "[] USPS 数据集\n",
    "\n",
    "[] 加噪 1000 步，选取个别节点\n",
    "\n",
    "0. []画图\n",
    "1. 数据集\n",
    "   - [√] FMNIST, MNIST\n",
    "   - [] comic_faces_v1\n",
    "2. 多种渐变方式\n",
    "   - [√] 扩散(DDIM)：并无直接 X->Y 的分布转移渐变，只有 X->高斯->Y 分布。但高斯分布本身会造成严重距离聚集。\n",
    "   - [√] Flow(插值)：X->Y 分布转移渐变，纯粹生成一般随机采样高斯噪声作为 X。\n",
    "   - [] 薛定谔桥：同 Flow\n",
    "3. []级联 OT\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
